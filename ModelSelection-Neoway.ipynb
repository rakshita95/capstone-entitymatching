{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neoway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('/anaconda/lib/python3.6/site-packages')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules.preprocessing import load_word_embedding_model\n",
    "from modules.preprocessing import Preprocessing\n",
    "from modules.preprocessing.generate_labels import gen_labels\n",
    "from modules.feature_generation.gen_similarities import similarities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.preprocessing import Preprocessor\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,  precision_score, recall_score, f1_score\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on sample data to find best model using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdf1 train shape:  (126, 5) \n",
      " \tmatch train shape:  (9, 2) \n",
      "\tdf1 test shape:  (63, 5) \n",
      "\tmatch test shape:  (7, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "read data\n",
    "'''\n",
    "df1 = pd.read_csv('data/companies_data_neoway_subsample/input.csv')\n",
    "df2 = pd.read_csv('data/companies_data_neoway_subsample/reference.csv')\n",
    "match_df = pd.read_csv('data/companies_data_neoway_subsample/match.csv')\n",
    "\n",
    "'''\n",
    "specify id names\n",
    "'''\n",
    "df1_id = 'serial'\n",
    "df2_id = 'serial'\n",
    "match_id1 = 'serial_input' #corresponds to df1_id\n",
    "match_id2 = 'serial_reference' #corresponds to df2_id\n",
    "\n",
    "'''\n",
    "train/test split on input dataset\n",
    "'''\n",
    "#random split inputs into train/test using original dataset\n",
    "df1_train, df1_test = train_test_split(df1, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "#set index dic\n",
    "df1_train_index = dict(zip(df1_train[df1_id], df1_train.reset_index().index))\n",
    "df1_test_index = dict(zip(df1_test[df1_id], df1_test.reset_index().index))\n",
    "\n",
    "'''\n",
    "id column manipulation\n",
    "'''\n",
    "# save for later use to generate labels\n",
    "df1_train_id_col = df1_train[df1_id]\n",
    "df1_test_id_col = df1_test[df1_id]\n",
    "df2_id_col = df2[df2_id]\n",
    "\n",
    "match_train = match_df[match_df[match_id1].isin(df1_train_id_col)]\n",
    "match_test = match_df[match_df[match_id1].isin(df1_test_id_col)]\n",
    "\n",
    "#drop id columns because we don't need to compute id similarity\n",
    "df1_train = df1_train.drop(columns = [df1_id])\n",
    "df1_test = df1_test.drop(columns = [df1_id])\n",
    "df2 = df2.drop(columns = [df2_id])\n",
    "\n",
    "print('\\tdf1 train shape: ', df1_train.shape, '\\n',\n",
    "      '\\tmatch train shape: ', match_train.shape, '\\n'\n",
    "      '\\tdf1 test shape: ', df1_test.shape, '\\n'\n",
    "      '\\tmatch test shape: ', match_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***preprocessing***\n",
      "**** df1 divide columns ****\n",
      "numerical_cols :  ['addressZip']\n",
      "special_field_cols :  ['name' 'addressStreet' 'addressZip']\n",
      "word_embedding_cols :  ['name' 'addressStreet' 'addressCity' 'addressState']\n",
      "\n",
      " **** df2 divide columns ****\n",
      "numerical_cols :  ['addressZip']\n",
      "special_field_cols :  ['name' 'addressStreet' 'addressZip']\n",
      "word_embedding_cols :  ['name' 'addressStreet' 'addressCity' 'addressState']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshitanagalla/Desktop/capstone-entitymatching/modules/preprocessing/preprocess_special_columns.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[a] = df[a].astype(str)\n",
      "/Users/rakshitanagalla/Desktop/capstone-entitymatching/modules/preprocessing/preprocess_special_columns.py:109: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return df.astype(str).as_matrix(), None, None\n",
      "/Users/rakshitanagalla/Desktop/capstone-entitymatching/modules/preprocessing/__init__.py:349: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  df1_numeric = df1_numeric.as_matrix().astype(float)\n",
      "/Users/rakshitanagalla/Desktop/capstone-entitymatching/modules/preprocessing/__init__.py:350: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  df2_numeric = df2_numeric.as_matrix().astype(float)\n"
     ]
    }
   ],
   "source": [
    "print(\"***preprocessing***\")\n",
    "\n",
    "processor = Preprocessor(special_columns=['name','addressStreet'],zip_code = \"addressZip\")\n",
    "processor.fit(df1_train,df2) #fitting on training dataset for input and on whole dataset for ref\n",
    "\n",
    "processed_train = processor.transform(df1_train, df2)\n",
    "processed_test = processor.transform(df1_test, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_x(processed_data):\n",
    "\n",
    "    '''\n",
    "    get numerical data\n",
    "    '''\n",
    "\n",
    "    num_matrix_1, num_matrix_2 = processed_data[\"numerical\"][0],processed_data[\"numerical\"][1]\n",
    "    embed_matrix_1, embed_matrix_2 = processed_data[\"word_embedding_fields\"][0],processed_data[\"word_embedding_fields\"][1]\n",
    "    spc_matrix_1, spc_matrix_2 = processed_data[\"special_fields\"][0],processed_data[\"special_fields\"][1]\n",
    "\n",
    "    '''\n",
    "    calculate similarities\n",
    "    '''\n",
    "\n",
    "    num_sg_data = similarities().numerical_similarity_on_matrix(num_matrix_1,num_matrix_2,method = \"scaled_gaussian\")\n",
    "    num_mm_data = similarities().numerical_similarity_on_matrix(num_matrix_1,num_matrix_2,method = \"min_max\")\n",
    "    embed_tfidf_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_mean_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_min_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_max_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    spc_lav_data = similarities().text_similarity_on_matrix(spc_matrix_1,spc_matrix_2, method = \"lavenshtein\")\n",
    "    spc_jw_data = similarities().text_similarity_on_matrix(spc_matrix_1, spc_matrix_2, method=\"jaro_winkler\")\n",
    "    spc_jc_data = similarities().text_similarity_on_matrix(spc_matrix_1, spc_matrix_2, method=\"jaccard\")\n",
    "    '''\n",
    "    concatenate all data\n",
    "    '''\n",
    "    # only concatenate non-empty similarity matrices\n",
    "    non_empty = []\n",
    "\n",
    "    for m in num_sg_data, num_mm_data, embed_tfidf_data, spc_lav_data, spc_jw_data, spc_jc_data:\n",
    "        if m.size !=0:\n",
    "            non_empty.append(m)\n",
    "\n",
    "    x = np.concatenate([i for i in non_empty], axis = 1)\n",
    "\n",
    "    print(x.shape)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46242, 15)\n",
      "(23121, 15)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "generate features\n",
    "'''\n",
    "x_train = gen_x(processed_train)\n",
    "x_test = gen_x(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "generate labels\n",
    "'''\n",
    "# generate y labels\n",
    "y_train = gen_labels(df1_train_id_col, df2_id_col, match_train, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_train.shape[0] == x_train.shape[0])\n",
    "print(y_train.sum() == match_train.shape[0])\n",
    "\n",
    "# generate y labels\n",
    "y_test = gen_labels(df1_test_id_col, df2_id_col, match_test, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_test.shape[0] == x_test.shape[0])\n",
    "print(y_test.sum() == match_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Impute\n",
    "'''\n",
    "col_means = np.nanmean(x_train,axis=0)\n",
    "inds_train  = np.where(np.isnan(x_train))\n",
    "inds_test = np.where(np.isnan(x_test))\n",
    "x_train[inds_train]=np.take(col_means, inds_train[1])\n",
    "x_test[inds_test]=np.take(col_means, inds_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import svm\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=3,scoring='f1')\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid = {'max_depth': np.arange(3, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=3,scoring='f1')\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Sample Test-set Score (Old Definition)\n",
      "\tPrecision: 1.000\n",
      "\tRecall: 0.857\n",
      "\tF1: 0.923\n",
      "\tAccuracy: 0.9999567492755503\n",
      "SVC Sample Test-set Score (Old Definition)\n",
      "\tPrecision: 1.000\n",
      "\tRecall: 0.286\n",
      "\tF1: 0.444\n",
      "\tAccuracy: 0.9997837463777518\n",
      "DT Sample Test-set Score (Old Definition)\n",
      "\tPrecision: 1.000\n",
      "\tRecall: 0.429\n",
      "\tF1: 0.600\n",
      "\tAccuracy: 0.9998269971022015\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "RF\n",
    "'''\n",
    "rf_random = RandomForestClassifier(n_estimators=300,\n",
    "                                    min_samples_split=5,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    max_features='sqrt', max_depth=40,\n",
    "                                    class_weight='balanced',\n",
    "                                    bootstrap=False, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_test)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF Sample Test-set Score (Old Definition)')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_test)/len(y_test)))\n",
    "\n",
    "'''\n",
    "SVM\n",
    "'''\n",
    "svc_random = svm.SVC(kernel='rbf', C=10, gamma=0.01, random_state=42, probability=True)\n",
    "svc_random.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred_svc = svc_random.predict(x_test)\n",
    "y_pred_prob_svc = svc_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, y_pred_prob_svc)\n",
    "# precision, recall, f1\n",
    "print('SVC Sample Test-set Score (Old Definition)')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_svc))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_svc))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_svc))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_svc==y_test)/len(y_test)))\n",
    "\n",
    "'''\n",
    "DT\n",
    "'''\n",
    "dt_random = DecisionTreeClassifier(max_depth=7, random_state=42)\n",
    "\n",
    "dt_random.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred_dt = dt_random.predict(x_test)\n",
    "y_pred_prob_dt = dt_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_prob_dt)\n",
    "# precision, recall, f1\n",
    "print('DT Sample Test-set Score (Old Definition)')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_dt))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_dt))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_dt))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_dt==y_test)/len(y_test)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, 'r',label='RF')\n",
    "plt.plot(fpr_dt, tpr_dt, 'g',label='DT')\n",
    "plt.plot(fpr_svc, tpr_svc, 'b',label='SVC')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - Firmographic')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_orig_labels(pred_df, true_match_df, df1_id_col, match_id1, df2_id_col, match_id2):\n",
    "    \n",
    "    match = true_match_df.dropna()\n",
    "    match['true_label']=1\n",
    "\n",
    "    mat = pred_df[pred_df['prob']>0.5]\n",
    "    pred_match = mat.loc[mat.groupby(match_id1)['prob'].idxmax()]\n",
    "    pred_match['pred_label']=1\n",
    "\n",
    "    id_ = pd.DataFrame(df1_id_col)\n",
    "    id_.columns=[match_id1]\n",
    "\n",
    "    tmp = pred_match.merge(match, how = 'outer')\n",
    "    tmp = tmp.merge(id_,how='outer')\n",
    "    tmp['pred_label'] = tmp['pred_label'].fillna(0).astype(int)\n",
    "    #tmp = tmp.loc[tmp.groupby(match_id1)['pred_label'].idxmin()]\n",
    "\n",
    "    tmp['true_label'] = tmp['true_label'].fillna(0).astype(int)\n",
    "    tmp=tmp.drop(columns=['prob'])\n",
    "    tmp = tmp.sort_values(by=[match_id1])\n",
    "        \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res =[]\n",
    "for idx, (id_1,id_2) in enumerate(itertools.product(list(df1_test_id_col), list(df2_id_col))):\n",
    "    res.append([id_1,id_2,y_pred_prob_rf[idx]])\n",
    "\n",
    "assert(len(res) == len(y_pred_prob_rf))    \n",
    "pred_match = pd.DataFrame(res, columns=[match_id1,match_id2,'prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = gen_orig_labels(pred_match, match_test,df1_test_id_col, match_id1, df2_id_col, match_id2)\n",
    "true_labels = result['true_label']\n",
    "pred_labels = result['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Sample Test-set Score -- Aligned with Neoway\n",
      "\tPrecision: 1.000\n",
      "\tRecall: 0.857\n",
      "\tF1: 0.923\n"
     ]
    }
   ],
   "source": [
    "print('RF Sample Test-set Score -- Aligned with Neoway')\n",
    "\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(true_labels, pred_labels))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(true_labels, pred_labels))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(true_labels, pred_labels))\n",
    "#print(\"\\tAccuracy: {}\".format(sum(pred==true)/len(true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run best model on sample size of 10,000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "read data\n",
    "'''\n",
    "df1 = pd.read_csv('data/companies_data_neoway/full/input.csv')\n",
    "df2 = pd.read_csv('data/companies_data_neoway/full/reference.csv')\n",
    "block = pd.read_csv('company_zipcode_blocked_test_10000000.csv')\n",
    "block = block.drop_duplicates() #in case there are duplicates in blocked.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: check blocking coverage\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "specify id names\n",
    "'''\n",
    "df1_id = 'serial'\n",
    "df2_id = 'serial'\n",
    "match_id1 = 'serial_input' #corresponds to df1_id\n",
    "match_id2 = 'serial_reference' #corresponds to df2_id\n",
    "\n",
    "\n",
    "#uncomment this block when sampling on company_zipcode_blocked.csv\n",
    "block_inputs = block['input_serial'].unique()\n",
    "df1 = df1[df1[df1_id].isin(block_inputs)]\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "\n",
    "'''\n",
    "train/test split on input dataset\n",
    "'''\n",
    "#random split inputs into train/test using original dataset\n",
    "df1_train, df1_test = train_test_split(df1, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "#set index dic\n",
    "df1_train_index = dict(zip(df1_train[df1_id], df1_train.reset_index().index))\n",
    "df1_test_index = dict(zip(df1_test[df1_id], df1_test.reset_index().index))\n",
    "\n",
    "'''\n",
    "id column manipulation\n",
    "'''\n",
    "# save for later use to generate labels\n",
    "df1_train_id_col = df1_train[df1_id]\n",
    "df1_test_id_col = df1_test[df1_id]\n",
    "df2_id_col = df2[df2_id]\n",
    "\n",
    "#drop id columns because we don't need to compute id similarity\n",
    "df1_train = df1_train.drop(columns = [df1_id])\n",
    "df1_test = df1_test.drop(columns = [df1_id])\n",
    "df2 = df2.drop(columns = [df2_id])\n",
    "\n",
    "#also split block into train/test according to df1_train and df1_test\n",
    "block_train = block[block['input_serial'].isin(df1_train_id_col)]\n",
    "block_test = block[block['input_serial'].isin(df1_test_id_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "preprocessing\n",
    "'''\n",
    "'''\n",
    "processor = Preprocessor(special_columns=['name','addressStreet'],zip_code='addressZip')\n",
    "processor.fit(df1_train,df2) #fitting on training dataset for input and on whole dataset for ref\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "func to generate feature matrix\n",
    "'''\n",
    "'''\n",
    "def get_feature_matrix(df1,df2,df1_index,block):\n",
    "    count = 0\n",
    "    df2_bool = df2_id_col.isin(block['refer_serial'].unique()) #extract only relevant ref data\n",
    "    df2 = df2[df2_bool]\n",
    "    df2_index = dict(zip(df2_id_col[df2_bool], df2.reset_index().index)) #set index dic\n",
    "    processed_data = processor.transform(df1,df2)\n",
    "    num_matrix_1,num_matrix_2 = processed_data[\"numerical\"][0],processed_data[\"numerical\"][1]\n",
    "    embed_matrix_1,embed_matrix_2 = processed_data[\"word_embedding_fields\"][0],processed_data[\"word_embedding_fields\"][1]\n",
    "    spc_matrix_1,spc_matrix_2 = processed_data[\"special_fields\"][0],processed_data[\"special_fields\"][1]\n",
    "    X = []\n",
    "    for i, r in block.iterrows():\n",
    "        row=[]\n",
    "        df1_i = df1_index[r['input_serial']]\n",
    "        df2_i = df2_index[r['refer_serial']]\n",
    "        row+=[similarities().numerical_similarity_on_matrix(num_matrix_1[[df1_i]],num_matrix_2[[df2_i]])]\n",
    "        row+=[similarities().vector_similarity_on_matrix(embed_matrix_1[[df1_i]],embed_matrix_2[[df2_i]])]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"lavenshtein\")]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"jaro_winkler\")]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"jaccard\")]\n",
    "        X+=[np.hstack(row)]\n",
    "        count += 1 #for checking progress\n",
    "        if count % 100000 == 0:\n",
    "            print(\"loop \"+str(count))\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    \n",
    "    return X\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "generate features\n",
    "'''\n",
    "'''\n",
    "x_train = get_feature_matrix(df1_train,df2,df1_train_index,block_train)\n",
    "print(\"***x_train done***\")\n",
    "x_test = get_feature_matrix(df1_test,df2,df1_test_index,block_test)\n",
    "print(\"***x_test done***\")\n",
    "'''\n",
    "'''\n",
    "save features\n",
    "'''\n",
    "'''\n",
    "np.save('neoway_x_train_10000000_blocking',x_train)\n",
    "#del x_train\n",
    "print(\"***x_train saved***\")\n",
    "\n",
    "np.save('neoway_x_test_10000000_blocking',x_test)\n",
    "#del x_test\n",
    "print(\"***x_test saved***\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "load features\n",
    "'''\n",
    "x_train = np.load('neoway_x_train_10000000_blocking.npy')\n",
    "x_test = np.load('neoway_x_test_10000000_blocking.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6585145, 14)\n",
      "(3414854, 14)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate labels\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "generate labels\n",
    "'''\n",
    "print('generate labels')\n",
    "mapping=pd.read_csv('data/companies_data_neoway/full/match.csv')\n",
    "mapping['label']=1\n",
    "\n",
    "y_train = pd.merge(block_train,mapping,left_on=['input_serial','refer_serial'],right_on=['serial_input','serial_reference'],how='left')\n",
    "#y_train = y_train.drop_duplicates() #bc some depulicates in abt_buy_perfectMapping.csv?\n",
    "y_train = y_train[\"label\"].fillna(0).astype(int)\n",
    "\n",
    "y_test = pd.merge(block_test,mapping,left_on=['input_serial','refer_serial'],right_on=['serial_input','serial_reference'],how='left')\n",
    "#y_test = y_test.drop_duplicates() #bc some depulicates in abt_buy_perfectMapping.csv?\n",
    "y_test = y_test[\"label\"].fillna(0).astype(int)\n",
    "\n",
    "print(y_train.shape[0] == x_train.shape[0])\n",
    "print(y_test.shape[0] == x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 6583872, 1: 1273})\n",
      "Counter({0: 3414238, 1: 616})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get validation set\n",
    "'''\n",
    "x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, stratify=y_train, test_size=0.2, random_state=42)\n",
    "print(sum(y_train_new))\n",
    "print(sum(y_val))\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "impute nan's\n",
    "'''\n",
    "col_means = np.nanmean(x_train_new,axis=0)\n",
    "inds_train  = np.where(np.isnan(x_train_new))\n",
    "inds_val = np.where(np.isnan(x_val))\n",
    "x_train_new[inds_train]=np.take(col_means, inds_train[1])\n",
    "x_val[inds_val]=np.take(col_means, inds_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***start modeling***\n",
      "training score\n",
      "RF\n",
      "\tPrecision: 0.895\n",
      "\tRecall: 1.000\n",
      "\tF1: 0.945\n",
      "\tAccuracy: 0.9999774112794783\n",
      "val score\n",
      "RF\n",
      "\tPrecision: 0.891\n",
      "\tRecall: 0.933\n",
      "\tF1: 0.912\n",
      "\tAccuracy: 0.9999650729027227\n"
     ]
    }
   ],
   "source": [
    "print(\"***start modeling***\")\n",
    "rf_random = RandomForestClassifier(n_estimators=300,\n",
    "                                    min_samples_split=5,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    max_features='sqrt', max_depth=40,\n",
    "                                    class_weight='balanced',\n",
    "                                    bootstrap=False, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random.fit(x_train_new, y_train_new)\n",
    "print(\"training score\")\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_train_new)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_train_new)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train_new, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_train_new)/len(y_train_new)))\n",
    "del x_train_new\n",
    "\n",
    "\n",
    "print(\"val score\")\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_val)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_val)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_val, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_val, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_val, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_val, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_val)/len(y_val)))\n",
    "del x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**not much overfitting, so evaluate on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "RF\n",
      "\tPrecision: 0.895\n",
      "\tRecall: 0.956\n",
      "\tF1: 0.925\n",
      "\tAccuracy: 0.9999718875243275\n"
     ]
    }
   ],
   "source": [
    "#impute nan's\n",
    "inds_test = np.where(np.isnan(x_test))\n",
    "x_test[inds_test]=np.take(col_means, inds_test[1])\n",
    "\n",
    "#generate labels and pred matrix\n",
    "y_test = pd.merge(block_test,mapping,left_on=['input_serial','refer_serial'],right_on=['serial_input','serial_reference'],how='left')\n",
    "pred_match_test = y_test[['input_serial','refer_serial']]\n",
    "y_test = y_test[\"label\"].fillna(0).astype(int)\n",
    "\n",
    "print(y_test.shape[0] == x_test.shape[0])\n",
    "\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_test)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# update pred matrix\n",
    "print(y_pred_prob_rf.shape[0] == pred_match_test.shape[0])\n",
    "pred_match_test['prob'] = y_pred_prob_rf\n",
    "\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of true matches\n",
      "616\n"
     ]
    }
   ],
   "source": [
    "print(\"num of true matches\")\n",
    "print(sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of predicted matches\n",
      "658\n"
     ]
    }
   ],
   "source": [
    "print(\"num of predicted matches\")\n",
    "print(sum(y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_orig_labels(pred_df, true_match_df, df1_id_col, match_id1, df2_id_col, match_id2):\n",
    "    \n",
    "    match = true_match_df.dropna()\n",
    "    match.columns = [match_id1, match_id2,'true_label']\n",
    "    \n",
    "    #change column names to match w/ \"match\"\n",
    "    pred_df.columns = [match_id1, match_id2,'prob']\n",
    "    mat = pred_df[pred_df['prob']>0.5]\n",
    "    pred_match = mat.loc[mat.groupby(match_id1)['prob'].idxmax()]\n",
    "    pred_match['pred_label']=1\n",
    "\n",
    "    id_ = pd.DataFrame(df1_id_col)\n",
    "    id_.columns=[match_id1]\n",
    "\n",
    "    tmp = pred_match.merge(match, how = 'outer')\n",
    "    tmp = tmp.merge(id_,how='outer')\n",
    "    tmp['pred_label'] = tmp['pred_label'].fillna(0).astype(int)\n",
    "    #tmp = tmp.loc[tmp.groupby(match_id1)['pred_label'].idxmin()]\n",
    "\n",
    "    tmp['true_label'] = tmp['true_label'].fillna(0).astype(int)\n",
    "    tmp=tmp.drop(columns=['prob'])\n",
    "    tmp = tmp.sort_values(by=[match_id1])\n",
    "        \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_test = mapping[mapping[match_id1].isin(df1_test_id_col)]\n",
    "result = gen_orig_labels(pred_match_test, match_test, df1_test_id_col, match_id1, df2_id_col, match_id2)\n",
    "true_labels = result['true_label']\n",
    "pred_labels = result['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Sample Test-set Score -- Aligned with Neoway\n",
      "\tPrecision: 0.964\n",
      "\tRecall: 0.924\n",
      "\tF1: 0.944\n"
     ]
    }
   ],
   "source": [
    "print('RF Sample Test-set Score -- Aligned with Neoway')\n",
    "\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(true_labels, pred_labels))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(true_labels, pred_labels))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(true_labels, pred_labels))\n",
    "#print(\"\\tAccuracy: {}\".format(sum(pred==true)/len(true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run best model on full datasets¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdf1 train shape:  (17218, 5) \n",
      " \tmatch train shape:  (9, 2) \n",
      "\tdf1 test shape:  (8481, 5) \n",
      "\tmatch test shape:  (7, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "read data\n",
    "'''\n",
    "df1 = pd.read_csv('data/companies_data_neoway/full/input.csv')\n",
    "df2 = pd.read_csv('data/companies_data_neoway/full/reference.csv')\n",
    "block = pd.read_csv('data/company_zipcode_blocked.csv')\n",
    "block = block.drop_duplicates() #in case there are duplicates in blocked.csv\n",
    "\n",
    "'''\n",
    "specify id names\n",
    "'''\n",
    "df1_id = 'serial'\n",
    "df2_id = 'serial'\n",
    "match_id1 = 'serial_input' #corresponds to df1_id\n",
    "match_id2 = 'serial_reference' #corresponds to df2_id\n",
    "\n",
    "'''\n",
    "train/test split on input dataset\n",
    "'''\n",
    "#random split inputs into train/test using original dataset\n",
    "df1_train, df1_test = train_test_split(df1, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "#set index dic\n",
    "df1_train_index = dict(zip(df1_train[df1_id], df1_train.reset_index().index))\n",
    "df1_test_index = dict(zip(df1_test[df1_id], df1_test.reset_index().index))\n",
    "\n",
    "'''\n",
    "id column manipulation\n",
    "'''\n",
    "# save for later use to generate labels\n",
    "df1_train_id_col = df1_train[df1_id]\n",
    "df1_test_id_col = df1_test[df1_id]\n",
    "df2_id_col = df2[df2_id]\n",
    "\n",
    "#drop id columns because we don't need to compute id similarity\n",
    "df1_train = df1_train.drop(columns = [df1_id])\n",
    "df1_test = df1_test.drop(columns = [df1_id])\n",
    "df2 = df2.drop(columns = [df2_id])\n",
    "\n",
    "#also split block into train/test according to df1_train and df1_test\n",
    "block_train = block[block['input_serial'].isin(df1_train_id_col)]\n",
    "block_test = block[block['input_serial'].isin(df1_test_id_col)]\n",
    "\n",
    "print('\\tdf1 train shape: ', df1_train.shape, '\\n',\n",
    "      '\\tmatch train shape: ', match_train.shape, '\\n'\n",
    "      '\\tdf1 test shape: ', df1_test.shape, '\\n'\n",
    "      '\\tmatch test shape: ', match_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "preprocessing\n",
    "'''\n",
    "'''\n",
    "processor = Preprocessor(special_columns=['name','addressStreet'],zip_code='addressZip')\n",
    "processor.fit(df1_train,df2) #fitting on training dataset for input and on whole dataset for ref\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "func to generate feature matrix\n",
    "'''\n",
    "'''\n",
    "def get_feature_matrix(df1,df2,df1_index,block):\n",
    "    count = 0\n",
    "    df2_bool = df2_id_col.isin(block['refer_serial'].unique()) #extract only relevant ref data\n",
    "    df2 = df2[df2_bool]\n",
    "    df2_index = dict(zip(df2_id_col[df2_bool], df2.reset_index().index)) #set index dic\n",
    "    processed_data = processor.transform(df1,df2)\n",
    "    num_matrix_1,num_matrix_2 = processed_data[\"numerical\"][0],processed_data[\"numerical\"][1]\n",
    "    embed_matrix_1,embed_matrix_2 = processed_data[\"word_embedding_fields\"][0],processed_data[\"word_embedding_fields\"][1]\n",
    "    spc_matrix_1,spc_matrix_2 = processed_data[\"special_fields\"][0],processed_data[\"special_fields\"][1]\n",
    "    X = []\n",
    "    for i, r in block.iterrows():\n",
    "        row=[]\n",
    "        df1_i = df1_index[r['input_serial']]\n",
    "        df2_i = df2_index[r['refer_serial']]\n",
    "        row+=[similarities().numerical_similarity_on_matrix(num_matrix_1[[df1_i]],num_matrix_2[[df2_i]])]\n",
    "        row+=[similarities().vector_similarity_on_matrix(embed_matrix_1[[df1_i]],embed_matrix_2[[df2_i]])]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"lavenshtein\")]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"jaro_winkler\")]\n",
    "        row+=[similarities().text_similarity_on_matrix(spc_matrix_1[[df1_i]],spc_matrix_2[[df2_i]],method = \"jaccard\")]\n",
    "        X+=[np.hstack(row)]\n",
    "        count += 1 #for checking progress\n",
    "        if count % 100000 == 0:\n",
    "            print(\"loop \"+str(count))\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    \n",
    "    return X\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "generate features\n",
    "'''\n",
    "'''\n",
    "x_train = get_feature_matrix(df1_train,df2,df1_train_index,block_train)\n",
    "print(\"***x_train done***\")\n",
    "x_test = get_feature_matrix(df1_test,df2,df1_test_index,block_test)\n",
    "print(\"***x_test done***\")\n",
    "'''\n",
    "'''\n",
    "save features\n",
    "'''\n",
    "'''\n",
    "np.save('neoway_x_train_blocking',x_train)\n",
    "#del x_train\n",
    "print(\"***x_train saved***\")\n",
    "\n",
    "np.save('neoway_x_test_blocking',x_test)\n",
    "#del x_test\n",
    "print(\"***x_test saved***\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***x_train loaded***\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load train features\n",
    "'''\n",
    "x_train = np.load('neoway_x_train_blocking.npy')\n",
    "print(\"***x_train loaded***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***generate labels***\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "generate labels\n",
    "'''\n",
    "print('***generate labels***')\n",
    "mapping=pd.read_csv('data/companies_data_neoway/full/match.csv')\n",
    "mapping['label']=1\n",
    "\n",
    "y_train = pd.merge(block_train,mapping,left_on=['input_serial','refer_serial'],right_on=['serial_input','serial_reference'],how='left')\n",
    "#y_train = y_train.drop_duplicates() #bc some depulicates in abt_buy_perfectMapping.csv?\n",
    "y_train = y_train[\"label\"].fillna(0).astype(int)\n",
    "\n",
    "print(y_train.shape[0] == x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13114\n",
      "3279\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get validation set\n",
    "'''\n",
    "x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, stratify=y_train, test_size=0.2, random_state=42)\n",
    "print(sum(y_train_new))\n",
    "print(sum(y_val))\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "impute nan's\n",
    "'''\n",
    "col_means = np.nanmean(x_train_new,axis=0)\n",
    "inds_train  = np.where(np.isnan(x_train_new))\n",
    "inds_val = np.where(np.isnan(x_val))\n",
    "x_train_new[inds_train]=np.take(col_means, inds_train[1])\n",
    "x_val[inds_val]=np.take(col_means, inds_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***start modeling***\n"
     ]
    }
   ],
   "source": [
    "print(\"***start modeling***\")\n",
    "rf_random = RandomForestClassifier(n_estimators=300,\n",
    "                                    min_samples_split=5,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    max_features='sqrt', max_depth=40,\n",
    "                                    class_weight='balanced',\n",
    "                                    bootstrap=False, random_state=42, n_jobs=1)\n",
    "\n",
    "rf_random.fit(x_train_new, y_train_new)\n",
    "print(\"training score\")\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_train_new)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_train_new)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train_new, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_train_new, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_train_new)/len(y_train_new)))\n",
    "del x_train_new\n",
    "\n",
    "\n",
    "print(\"val score\")\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_val)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_val)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_val, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_val, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_val, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_val, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_val)/len(y_val)))\n",
    "del x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**not much overfitting, so evaluate on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.load('neoway_x_test_blocking.npy')\n",
    "print(\"***x_test loaded***\")\n",
    "\n",
    "#impute nan's\n",
    "inds_test = np.where(np.isnan(x_test))\n",
    "x_test[inds_test]=np.take(col_means, inds_test[1])\n",
    "\n",
    "#generate labels\n",
    "y_test = pd.merge(block_test,mapping,left_on=['input_serial','refer_serial'],right_on=['serial_input','serial_reference'],how='left')\n",
    "y_test = y_test[\"label\"].fillna(0).astype(int)\n",
    "\n",
    "print(y_test.shape[0] == x_test.shape[0])\n",
    "\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_test)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "import pickle\n",
    "with open('neoway_rf_blocking_final.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf_random, fid, protocol=4)\n",
    "\n",
    "print(\"***model saved***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
