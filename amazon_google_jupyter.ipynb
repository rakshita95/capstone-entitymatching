{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon - Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('/anaconda/lib/python3.6/site-packages')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules.preprocessing import load_word_embedding_model\n",
    "from modules.preprocessing import Preprocessing\n",
    "from modules.preprocessing.generate_labels import gen_labels\n",
    "from modules.feature_generation.gen_similarities import similarities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on sample data to find best model using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "read data\n",
    "'''\n",
    "# df1 = pd.read_csv(\"data/amazon_google/full/Amazon.csv\",engine='python')\n",
    "# df2 = pd.read_csv(\"data/amazon_google/full/GoogleProducts.csv\", engine='python')\n",
    "# match_df = pd.read_csv(\"data/amazon_google/full/Amzon_GoogleProducts_perfectMapping.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"data/amazon_google/sample/amazon_sample.csv\",engine='python')\n",
    "df2 = pd.read_csv(\"data/amazon_google/sample/google_sample.csv\", engine='python')\n",
    "match_df = pd.read_csv(\"data/amazon_google/sample/amazon_google_sample_match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdf1 train shape:  (76, 4) \n",
      " \tmatch train shape:  (22, 2) \n",
      "\tdf1 test shape:  (38, 4) \n",
      "\tmatch test shape:  (8, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "specify id names\n",
    "'''\n",
    "df1_id = 'id'\n",
    "df2_id = 'id'\n",
    "match_id1 = 'idAmazon' # corresponds to df1_id\n",
    "match_id2 = 'idGoogleBase' # corresponds to df2_id\n",
    "\n",
    "'''\n",
    "custom data cleaning, currently this section is for google dataset only\n",
    "we still need to convert currency. right now just ignoring currency effect\n",
    "'''\n",
    "df2[\"price\"] = df2.price.str.replace(r\"[a-zA-Z]\",'').astype(float)\n",
    "\n",
    "'''\n",
    "train/test split on input dataset\n",
    "'''\n",
    "#random split inputs into train/test using original dataset\n",
    "df1_train, df1_test = train_test_split(df1, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "#set index dic\n",
    "df1_train_index = dict(zip(df1_train[df1_id], df1_train.reset_index().index))\n",
    "df1_test_index = dict(zip(df1_test[df1_id], df1_test.reset_index().index))\n",
    "\n",
    "'''\n",
    "id column manipulation\n",
    "'''\n",
    "# save for later use to generate labels\n",
    "df1_train_id_col = df1_train[df1_id]\n",
    "df1_test_id_col = df1_test[df1_id]\n",
    "df2_id_col = df2[df2_id]\n",
    "\n",
    "match_train = match_df[match_df['idAmazon'].isin(df1_train_id_col)]\n",
    "match_test = match_df[match_df['idAmazon'].isin(df1_test_id_col)]\n",
    "\n",
    "#drop id columns because we don't need to compute id similarity\n",
    "df1_train = df1_train.drop(columns = [df1_id])\n",
    "df1_test = df1_test.drop(columns = [df1_id])\n",
    "df2 = df2.drop(columns = [df2_id])\n",
    "\n",
    "print('\\tdf1 train shape: ', df1_train.shape, '\\n',\n",
    "      '\\tmatch train shape: ', match_train.shape, '\\n'\n",
    "      '\\tdf1 test shape: ', df1_test.shape, '\\n'\n",
    "      '\\tmatch test shape: ', match_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** df1 divide columns ****\n",
      "numerical_cols :  ['price']\n",
      "special_field_cols :  ['title' 'manufacturer']\n",
      "word_embedding_cols :  ['title' 'description' 'manufacturer']\n",
      "\n",
      " **** df2 divide columns ****\n",
      "numerical_cols :  ['price']\n",
      "special_field_cols :  ['name' 'manufacturer']\n",
      "word_embedding_cols :  ['name' 'description' 'manufacturer']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "preprocess both dataframes\n",
    "'''\n",
    "\n",
    "glove = load_word_embedding_model('glove')\n",
    "processor = Preprocessor(special_columns=['title','manufacturer'],word_embedding_model_instance=glove)\n",
    "processor.fit(df1_train,df2) #fitting on training dataset for input and on whole dataset for ref\n",
    "\n",
    "processed_train = processor.transform(df1_train, df2)\n",
    "processed_test = processor.transform(df1_test, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_x(processed_data):\n",
    "\n",
    "    '''\n",
    "    get numerical data\n",
    "    '''\n",
    "\n",
    "    num_matrix_1, num_matrix_2 = processed_data[\"numerical\"][0],processed_data[\"numerical\"][1]\n",
    "    embed_matrix_1, embed_matrix_2 = processed_data[\"word_embedding_fields\"][0],processed_data[\"word_embedding_fields\"][1]\n",
    "    spc_matrix_1, spc_matrix_2 = processed_data[\"special_fields\"][0],processed_data[\"special_fields\"][1]\n",
    "\n",
    "    '''\n",
    "    calculate similarities\n",
    "    '''\n",
    "\n",
    "    num_sg_data = similarities().numerical_similarity_on_matrix(num_matrix_1,num_matrix_2,method = \"scaled_gaussian\")\n",
    "    num_mm_data = similarities().numerical_similarity_on_matrix(num_matrix_1,num_matrix_2,method = \"min_max\")\n",
    "    embed_tfidf_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_mean_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_min_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    #embed_max_data = similarities().vector_similarity_on_matrix(embed_matrix_1,embed_matrix_2)\n",
    "    spc_lav_data = similarities().text_similarity_on_matrix(spc_matrix_1,spc_matrix_2, method = \"lavenshtein\")\n",
    "    spc_jw_data = similarities().text_similarity_on_matrix(spc_matrix_1, spc_matrix_2, method=\"jaro_winkler\")\n",
    "    spc_jc_data = similarities().text_similarity_on_matrix(spc_matrix_1, spc_matrix_2, method=\"jaccard\")\n",
    "    '''\n",
    "    concatenate all data\n",
    "    '''\n",
    "    # only concatenate non-empty similarity matrices\n",
    "    non_empty = []\n",
    "\n",
    "    for m in num_sg_data, num_mm_data, embed_tfidf_data, spc_lav_data, spc_jw_data, spc_jc_data:\n",
    "        if m.size !=0:\n",
    "            non_empty.append(m)\n",
    "\n",
    "    x = np.concatenate([i for i in non_empty], axis = 1)\n",
    "\n",
    "    print(x.shape)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15200, 11)\n",
      "(7600, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsave features\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = gen_x(processed_train)\n",
    "x_test = gen_x(processed_test)\n",
    "\n",
    "'''\n",
    "save features\n",
    "'''\n",
    "# np.save('amz_ggl_x_train',x_train)\n",
    "# #del x_train\n",
    "\n",
    "# print(\"***x_train saved***\")\n",
    "\n",
    "# np.save('amz_ggl_x_test',x_test)\n",
    "# #del x_test\n",
    "\n",
    "# print(\"***x_test saved***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train test split\n",
    "'''\n",
    "# generate y labels\n",
    "y_train = gen_labels(df1_train_id_col, df2_id_col, match_train, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_train.shape[0] == x_train.shape[0])\n",
    "print(y_train.sum() == match_train.shape[0])\n",
    "\n",
    "# generate y labels\n",
    "y_test = gen_labels(df1_test_id_col, df2_id_col, match_test, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_test.shape[0] == x_test.shape[0])\n",
    "print(y_test.sum() == match_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [300], 'max_features': ['sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False], 'class_weight': [None, 'balanced', 'balanced_subsample']}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 70, 'class_weight': 'balanced_subsample', 'bootstrap': False}\n",
      "\tMean CV f1-score : 0.600\n",
      "RF Sample Score (Old Definition)\n",
      "\tPrecision: 0.625\n",
      "\tRecall: 0.625\n",
      "\tF1: 0.625\n",
      "\tAccuracy: 0.9992105263157894\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "modeling\n",
    "'''\n",
    "col_means = np.nanmean(x_train, axis=0)\n",
    "inds_train = np.where(np.isnan(x_train))\n",
    "inds_test = np.where(np.isnan(x_test))\n",
    "x_train[inds_train]=np.take(col_means, inds_train[1])\n",
    "x_test[inds_test]=np.take(col_means, inds_test[1])\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,  precision_score, recall_score, f1_score\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# #upsample\n",
    "# x_maj = x_train[y_train==0]\n",
    "# x_min = x_train[y_train==1]\n",
    "# x_min_upsampled = resample(x_min,n_samples=x_maj.shape[0],random_state=42)\n",
    "# x_train_new = np.vstack((x_maj, x_min_upsampled))\n",
    "# y_train_new = np.hstack((np.zeros(x_maj.shape[0]), np.ones(x_maj.shape[0])))\n",
    "\n",
    "n_estimators = [300]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Class weights for class imbalance issue\n",
    "class_weight = [None, \"balanced\", \"balanced_subsample\"]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': class_weight}\n",
    "print(random_grid)\n",
    "# Use the random grid to search for best hyperparameters\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters and use all available cores\n",
    "random_search = RandomizedSearchCV(estimator=rf,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=100,\n",
    "                               cv=3, verbose=2, random_state=42,\n",
    "                               n_jobs=-1, scoring='f1')\n",
    "random_search.fit(x_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "print(\"\\tMean CV f1-score : %1.3f\" % random_search.best_score_ )\n",
    "# fit\n",
    "rf_random = random_search.best_estimator_\n",
    "# rf_random = RandomForestClassifier(n_estimators=300,\n",
    "#                                   min_samples_split=5,\n",
    "#                                   min_samples_leaf=1,\n",
    "#                                   max_features='sqrt', max_depth=90,\n",
    "#                                   bootstrap=True, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_test)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF Sample Score (Old Definition)')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_orig_labels(df1_id, match_id1, df2_id, match_id2, match, y_pred_prob):\n",
    "    match = match.dropna()\n",
    "    true_label=df1_id.isin(match[match_id1]).astype(int)\n",
    "    import itertools\n",
    "    res =[]\n",
    "    for idx, (id_1,id_2) in enumerate(itertools.product(list(df1_id), list(df2_id))):\n",
    "        res.append([id_1,id_2,y_pred_prob[idx]])\n",
    "    \n",
    "    match = pd.DataFrame(res, columns=[match_id1,match_id2,'prob'])\n",
    "    match = match[match['prob']>0.5]\n",
    "    pred_match = match.loc[match.groupby(match_id1)['prob'].idxmax()]\n",
    "    pred_label = df1_test_id_col.isin(pred_match[match_id1]).astype(int)\n",
    "    \n",
    "    return np.array(true_label), np.array(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true, pred = gen_orig_labels(df1_test_id_col, match_id1, df2_id_col, match_id2, match_test, y_pred_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Sample Score -- Aligned with Neoway\n",
      "\tPrecision: 0.625\n",
      "\tRecall: 0.625\n",
      "\tF1: 0.625\n",
      "\tAccuracy: 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "print('RF Sample Score -- Aligned with Neoway')\n",
    "\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(true, pred))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(true, pred))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(true, pred))\n",
    "print(\"\\tAccuracy: {}\".format(sum(pred==true)/len(true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run best model on full datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "read data\n",
    "'''\n",
    "df1 = pd.read_csv(\"data/amazon_google/full/Amazon.csv\",engine='python')\n",
    "df2 = pd.read_csv(\"data/amazon_google/full/GoogleProducts.csv\", engine='python')\n",
    "match_df = pd.read_csv(\"data/amazon_google/full/Amzon_GoogleProducts_perfectMapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "specify id names\n",
    "'''\n",
    "df1_id = 'id'\n",
    "df2_id = 'id'\n",
    "match_id1 = 'idAmazon' # corresponds to df1_id\n",
    "match_id2 = 'idGoogleBase' # corresponds to df2_id\n",
    "\n",
    "'''\n",
    "custom data cleaning, currently this section is for google dataset only\n",
    "we still need to convert currency. right now just ignoring currency effect\n",
    "'''\n",
    "df2[\"price\"] = df2.price.str.replace(r\"[a-zA-Z]\",'').astype(float)\n",
    "\n",
    "'''\n",
    "train/test split on input dataset\n",
    "'''\n",
    "#random split inputs into train/test using original dataset\n",
    "df1_train, df1_test = train_test_split(df1, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "#set index dic\n",
    "df1_train_index = dict(zip(df1_train[df1_id], df1_train.reset_index().index))\n",
    "df1_test_index = dict(zip(df1_test[df1_id], df1_test.reset_index().index))\n",
    "\n",
    "'''\n",
    "id column manipulation\n",
    "'''\n",
    "# save for later use to generate labels\n",
    "df1_train_id_col = df1_train[df1_id]\n",
    "df1_test_id_col = df1_test[df1_id]\n",
    "df2_id_col = df2[df2_id]\n",
    "\n",
    "match_train = match_df[match_df['idAmazon'].isin(df1_train_id_col)]\n",
    "match_test = match_df[match_df['idAmazon'].isin(df1_test_id_col)]\n",
    "\n",
    "#drop id columns because we don't need to compute id similarity\n",
    "df1_train = df1_train.drop(columns = [df1_id])\n",
    "df1_test = df1_test.drop(columns = [df1_id])\n",
    "df2 = df2.drop(columns = [df2_id])\n",
    "\n",
    "print('\\tdf1 train shape: ', df1_train.shape, '\\n',\n",
    "      '\\tmatch train shape: ', match_train.shape, '\\n'\n",
    "      '\\tdf1 test shape: ', df1_test.shape, '\\n'\n",
    "      '\\tmatch test shape: ', match_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "preprocess both dataframes\n",
    "'''\n",
    "\n",
    "glove = load_word_embedding_model('glove')\n",
    "processor = Preprocessor(special_columns=['title','manufacturer'],word_embedding_model_instance=glove)\n",
    "processor.fit(df1_train,df2) #fitting on training dataset for input and on whole dataset for ref\n",
    "\n",
    "processed_train = processor.transform(df1_train, df2)\n",
    "processed_test = processor.transform(df1_test, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = gen_x(processed_train)\n",
    "x_test = gen_x(processed_test)\n",
    "\n",
    "'''\n",
    "save features\n",
    "'''\n",
    "np.save('amz_ggl_x_train',x_train)\n",
    "#del x_train\n",
    "\n",
    "print(\"***x_train saved***\")\n",
    "\n",
    "np.save('amz_ggl_x_test',x_test)\n",
    "#del x_test\n",
    "\n",
    "print(\"***x_test saved***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train test split\n",
    "'''\n",
    "# generate y labels\n",
    "y_train = gen_labels(df1_train_id_col, df2_id_col, match_train, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_train.shape[0] == x_train.shape[0])\n",
    "print(y_train.sum() == match_train.shape[0])\n",
    "\n",
    "# generate y labels\n",
    "y_test = gen_labels(df1_test_id_col, df2_id_col, match_test, match_id1, match_id2)\n",
    "\n",
    "# simple check to see if x and y match in size\n",
    "print (y_test.shape[0] == x_test.shape[0])\n",
    "print(y_test.sum() == match_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "modeling\n",
    "'''\n",
    "col_means = np.nanmean(x_train, axis=0)\n",
    "inds_train = np.where(np.isnan(x_train))\n",
    "inds_test = np.where(np.isnan(x_test))\n",
    "x_train[inds_train]=np.take(col_means, inds_train[1])\n",
    "x_test[inds_test]=np.take(col_means, inds_test[1])\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,  precision_score, recall_score, f1_score\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# fit\n",
    "rf_random = random_search.best_estimator_\n",
    "# rf_random = RandomForestClassifier(n_estimators=300,\n",
    "#                                   min_samples_split=5,\n",
    "#                                   min_samples_leaf=1,\n",
    "#                                   max_features='sqrt', max_depth=90,\n",
    "#                                   bootstrap=True, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred_rf = rf_random.predict(x_test)\n",
    "y_pred_prob_rf = rf_random.predict_proba(x_test)[:, 1]\n",
    "# roc curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "# precision, recall, f1\n",
    "print('RF Full Dataset Score (Old Definition)')\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred_rf))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred_rf))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(y_test, y_pred_rf))\n",
    "print(\"\\tAccuracy: {}\".format(sum(y_pred_rf==y_test)/len(y_test)))\n",
    "\n",
    "# save the classifier\n",
    "import pickle\n",
    "with open('amz_ggl_rf.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf_random, fid, protocol=4)\n",
    "\n",
    "print(\"***model saved***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true, pred = gen_orig_labels(df1_test_id_col, match_id1, df2_id_col, match_id2, match_test, y_pred_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('RF Full Dataset Score -- Aligned with Neoway')\n",
    "\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(true, pred))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(true, pred))\n",
    "print(\"\\tF1: %1.3f\" % f1_score(true, pred))\n",
    "print(\"\\tAccuracy: {}\".format(sum(pred==true)/len(true)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c36",
   "language": "python",
   "name": "conda36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
